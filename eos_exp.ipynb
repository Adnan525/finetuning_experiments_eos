{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26b4009-6586-4235-afc3-f8993482a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from huggingface_hub import login\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcea4982-afae-426b-a1df-b37c18a9d478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/s448780/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\".env\")\n",
    "hf_token = os.getenv(\"hf_token\")\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de083d9-6f67-461d-80da-b57fd4af2922",
   "metadata": {},
   "source": [
    "# target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0c8885-da62-4154-a432-db455dafe49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39b8c9c-8428-49cd-9994-758fabb9f968",
   "metadata": {},
   "source": [
    "# quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e433057-0bc7-489e-b24e-a0a7cd1d9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "880e406b-6c59-47b6-a94b-e175397f65fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": [\n",
       "    128001,\n",
       "    128008,\n",
       "    128009\n",
       "  ],\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 14336,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 8.0,\n",
       "    \"high_freq_factor\": 4.0,\n",
       "    \"low_freq_factor\": 1.0,\n",
       "    \"original_max_position_embeddings\": 8192,\n",
       "    \"rope_type\": \"llama3\"\n",
       "  },\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.44.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "AutoConfig.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b45e63-91fd-4132-ab88-43ae7d26b960",
   "metadata": {},
   "source": [
    "# loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c488c236-cad4-4ff3-863a-c7707c6641f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3599f9931374e26b829d7be8f2e89e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c896072829c4a1382adf726d2dde154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa54ceb88ba7414ab4f734115f894f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af63517d046e450a826a19a5122b1242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c728e6d40bf84618923566a5e794d5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc2f139683d4a22800db5c3714eed87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3efbde36fe43e3bb25a5f20745eaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afa5047cc7c41a8a89085814fc9ea4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=bnb_config, \n",
    "    use_cache=False, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65cc4ab-f11d-4449-ab27-ffc7d8f7445f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ed968-de1a-424b-a1a9-4403e5a83687",
   "metadata": {},
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9659280-67c9-429b-b8c3-f78f679a8047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e34a026efd14630be432c21cb3aa240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040ddc93e0ec44808da108c2551adbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467ea505a7374c91ad80d3502b3e9ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id,\n",
    "                                          # add_bos_token = True, \n",
    "                                          padding_side = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e47826-7d0b-425d-b2d8-336a47d57a8b",
   "metadata": {},
   "source": [
    "# eos token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1438adc7-ba83-44cc-a274-703f095ea89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128009, '<|eot_id|>')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id, tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f46a4c-4e85-49ac-9f96-1c96408ed68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000, '<|begin_of_text|>')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id, tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c9c987-848c-484e-b834-a954dca7bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55fe3b19-57c9-4d31-bc70-8c7b4d1887d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|eot_id|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb075e8-182f-4f1b-98ab-eb5708c1d1c3",
   "metadata": {},
   "source": [
    "# stop ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9a2a5f6b-14e3-4830-ab8e-edd64c6d0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_ids = tokenizer([\".\", \"?\", \"!\"], return_tensors=\"pt\").input_ids.to(\"cuda:0\")\n",
    "# stop_ids = tokenizer([\"\\n\"], return_tensors=\"pt\").input_ids.to(\"cuda:0\")\n",
    "\n",
    "stop_ids = tokenizer([\"end_of_response\"], return_tensors=\"pt\").input_ids.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "39f2ee61-9944-4653-bf35-6617b727a44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(408, device='cuda:0')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_ids[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6e611ec-1729-4c2d-9588-7f382b654a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128009, 128009]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for llama 3.1\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "terminators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b51f57d-1223-450b-ab8c-7bde2a4737c8",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a96b6d-3df6-4160-9524-fbcf918faeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
       "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
       "            220,   1627,  10263,    220,   2366,     19,    271,  38195,   4320,\n",
       "            279,   3488,    304,    264,  64694,  11827,     13, 128009, 128006,\n",
       "            882, 128007,    271,  15546,  36592,  18200,     30, 128009, 128006,\n",
       "          78191, 128007,    271]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_ids = tokenizer('''Always answer the question in a concise manner.\n",
    "# You must not repeat the question and add eos_token only at the end of your response to the question.\n",
    "# who invented electricity?''', padding = True, return_tensors=\"pt\").input_ids.to(\"cuda:0\")\n",
    "# input_ids\n",
    "\n",
    "\n",
    "# for llama 3.1\n",
    "# https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Always answer the question in a concise manner.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who invented electricity?\"},\n",
    "]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "941b19bf-13f7-425a-8111-cb8ee031ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = torch.tensor([128000,  15546,  36592,  18200,     30, 128009])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e765f176-5c67-4d91-9326-f82941ebd452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.where(test == 128009, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35c1462c-1048-44f0-ab6d-dee9142eb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval() # dropout modules are deactivated\n",
    "# with torch.inference_mode():\n",
    "#     outputs = model.generate(\n",
    "#         input_ids=input_ids,\n",
    "#         # attention_mask = torch.where(input_ids == 128009, 0, 1),\n",
    "#         max_new_tokens=2048,\n",
    "#         # pad_token_id = tokenizer.eos_token_id,\n",
    "#         # do_sample=True, \n",
    "#         # top_p=0.9,\n",
    "#         # temperature=0.5,\n",
    "#         top_p = None,\n",
    "#         temperature = None,\n",
    "#         # eos_token_id = stop_ids[0][1]\n",
    "#     )\n",
    "\n",
    "# print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51aac3ce-7391-4f43-9769-431274cc3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=2048,\n",
    "    eos_token_id=terminators[0],\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19c47171-2ffa-4983-84cf-8f3a83df7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electricity is a naturally occurring phenomenon, and it's difficult to attribute its discovery to a single person. However, the understanding and harnessing of electricity as we know it today is often credited to Benjamin Franklin, who demonstrated the connection between lightning and electricity in the 18th century, and Michael Faraday, who made significant contributions to the understanding of electromagnetic induction.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(response, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e73437c1-d055-4cf7-87a9-edcb099687a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,  10263,    220,   2366,     19,    271,  38195,   4320,\n",
      "            279,   3488,    304,    264,  64694,  11827,     13, 128009, 128006,\n",
      "            882, 128007,    271,  15546,  36592,  18200,     30, 128009, 128006,\n",
      "          78191, 128007,    271,   3947,    374,    912,   3254,  72001,    315,\n",
      "          18200,     13,  74456,    374,    264,   5933,  25885,    430,    706,\n",
      "           1027,  13468,    323,  20041,    369,   9214,    315,   1667,     13,\n",
      "           4452,     11,   1401,  12678,   1093,  30411,  19372,    323,   8096,\n",
      "          13759,  65726,   1903,   5199,  19564,    311,   1057,   8830,    315,\n",
      "          18200,     13, 128009]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99408742-880d-40e6-98f4-1f604e0cb2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\nAlways answer the question in a concise manner.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWho invented electricity?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThere is no single inventor of electricity. Electricity is a natural phenomenon that has been observed and studied for thousands of years. However, key figures like Benjamin Franklin and Michael Faraday made significant contributions to our understanding of electricity.<|eot_id|>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a6907-e874-40f1-ac8f-aaf004796e84",
   "metadata": {},
   "source": [
    "# analysing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74a9b4a9-11b6-4fc3-a373-08c9503379f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 34,  43, 113]),)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list = np.array([item for sublist in outputs.to(\"cpu\") for item in sublist])\n",
    "np.where(flattened_list == 128009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9822e1b9-6f55-424c-85dd-5456ef665d67",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d5720ae-b788-44fc-940f-687b31c26425",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0effed51-39d2-4248-b3f6-866aa25ed4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference(\"Who invented electricity?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
